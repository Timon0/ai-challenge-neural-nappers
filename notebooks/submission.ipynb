{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from joblib import load\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modeling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Disable warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "NUM_STEPS = 20"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6d6a652091be522"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aadbd2fa6924bbdc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_features_chunk(series_id, periods=NUM_STEPS):\n",
    "    df = pd.read_parquet('../data/raw/train_series.parquet', filters=[('series_id','=',series_id)])\n",
    "    \n",
    "    print(df.shape)\n",
    "    print('Generating time features')\n",
    "    df[\"hour\"] = df['timestamp'].str[11:13]\n",
    "    \n",
    "    print('Generating statistical features')\n",
    "    df[\"anglez_abs\"] = abs(df[\"anglez\"])\n",
    "    df[\"anglez_diff\"] = df.groupby('series_id')['anglez'].diff(periods=periods).bfill().astype('float32')\n",
    "    df[\"enmo_diff\"] = df.groupby('series_id')['enmo'].diff(periods=periods).bfill().astype('float32')\n",
    "    df['anglez_x_enmo'] = df['anglez'] * df['enmo']\n",
    "    \n",
    "    print('Generating rolling features')\n",
    "    df[\"anglez_rolling_mean\"] = df[\"anglez\"].rolling(periods,center=True).mean().bfill().ffill().astype('float32')\n",
    "    df[\"enmo_rolling_mean\"] = df[\"enmo\"].rolling(periods,center=True).mean().bfill().ffill().astype('float32')\n",
    "    df[\"anglez_rolling_max\"] = df[\"anglez\"].rolling(periods,center=True).max().bfill().ffill().astype('float32')\n",
    "    df[\"enmo_rolling_max\"] = df[\"enmo\"].rolling(periods,center=True).max().bfill().ffill().astype('float32')\n",
    "    df[\"anglez_rolling_min\"] = df[\"anglez\"].rolling(periods,center=True).min().bfill().ffill().astype('float32')\n",
    "    df[\"enmo_rolling_min\"] = df[\"enmo\"].rolling(periods,center=True).min().bfill().ffill().astype('float32')\n",
    "    df[\"anglez_rolling_std\"] = df[\"anglez\"].rolling(periods,center=True).std().bfill().ffill().astype('float32')\n",
    "    df[\"enmo_rolling_std\"] = df[\"enmo\"].rolling(periods,center=True).std().bfill().ffill().astype('float32')    \n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8ebdc521ffadde6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet('../data/raw/test_series.parquet')\n",
    "#df_test = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f304a3a82bcbb301"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_features(test):\n",
    "    train_data = []\n",
    "\n",
    "    total_len = test.series_id.nunique()\n",
    "    series_ids = test.series_id.unique()\n",
    "    \n",
    "    del test\n",
    "    gc.collect()\n",
    "\n",
    "    for i, series_id in enumerate(series_ids):\n",
    "        print(f'Step {i+1} of {total_len}')\n",
    "        chunk = make_features_chunk(series_id)\n",
    "        train_data.append(chunk)\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    return pd.concat(train_data).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c70c17e9e1ece792"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_with_features = make_features(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dcbfa92ac011a01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del df_test\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95dfaa0061dc4ef5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = ['anglez', 'enmo', 'hour', 'anglez_abs', 'anglez_diff', 'enmo_diff', 'anglez_x_enmo', \n",
    "            'anglez_rolling_mean', 'enmo_rolling_mean', 'anglez_rolling_max',\n",
    "            'enmo_rolling_max', 'anglez_rolling_min', 'enmo_rolling_min',\n",
    "            'anglez_rolling_std', 'enmo_rolling_std']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37b0b816220ecc09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loading classifier\n",
    "dt_classifier = load('dt_classifier.joblib')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ae4febea7ab58fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the Events from the predictions with smoothing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d31c8fc4e2d8ab59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_events(test_series, classifier) :\n",
    "    \"\"\"\n",
    "    Takes a time series and a classifier and returns a formatted submission dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    series_ids = test_series['series_id'].unique()\n",
    "    events = []\n",
    "\n",
    "    for idx in series_ids: \n",
    "\n",
    "        # Collecting sample and normalizing features\n",
    "        X = test_series[test_series.series_id == idx]\n",
    "        \n",
    "        # Applying classifier to get predictions and scores\n",
    "        not_awake, awake = classifier.predict_proba(X[features])[:, 0], classifier.predict_proba(X[features])[:, 1]\n",
    "\n",
    "        X['not_awake'] = not_awake\n",
    "        X['awake'] = awake\n",
    "        \n",
    "        smoothing_length = 12 * 30 # 30 Minutes\n",
    "        X[\"score\"] = X[\"awake\"].rolling(smoothing_length, center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "        X[\"smooth\"] = X[\"not_awake\"].rolling(smoothing_length, center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "\n",
    "        # Binarize the smoothing column\n",
    "        X[\"smooth\"] = X[\"smooth\"].round()\n",
    "\n",
    "        # Getting predicted onset and wakeup time steps\n",
    "        pred_onsets = X[X['smooth'].diff() > 0]['step'].tolist()\n",
    "        pred_wakeups = X[X['smooth'].diff() < 0]['step'].tolist()\n",
    "     \n",
    "        if len(pred_onsets) > 0: \n",
    "\n",
    "            # Ensuring all predicted sleep periods begin and end\n",
    "            if min(pred_wakeups) < min(pred_onsets): \n",
    "                pred_wakeups = pred_wakeups[1:]\n",
    "\n",
    "            if max(pred_onsets) > max(pred_wakeups):\n",
    "                pred_onsets = pred_onsets[:-1]\n",
    "\n",
    "            # Keeping sleep periods longer than 30 minutes\n",
    "            sleep_periods = [(onset, wakeup) for onset, wakeup in zip(pred_onsets, pred_wakeups) if wakeup - onset >= 12 * 30]\n",
    "\n",
    "            for onset, wakeup in sleep_periods:\n",
    "                # Scoring using mean probability over period\n",
    "                score = X[(X['step'] >= onset) & (X['step'] <= wakeup)]['score'].mean()\n",
    "\n",
    "                # Adding sleep event to dataframe\n",
    "                onset_row = {'row_id': len(events), 'series_id': idx, 'step': onset, 'event': 'onset', 'score': score}                \n",
    "                events.append(onset_row)\n",
    "\n",
    "                wakeup_row = {'row_id': len(events), 'series_id': idx, 'step': wakeup, 'event': 'wakeup', 'score': score}\n",
    "                events.append(wakeup_row)\n",
    "\n",
    "        indexToDrop = test_series[test_series.series_id == idx].index\n",
    "        test_series.drop(indexToDrop, inplace=True)\n",
    "        del X\n",
    "        gc.collect()\n",
    "\n",
    "    return pd.DataFrame(events)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fec2e186c3f6f27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submissions = get_events(test_with_features, dt_classifier)\n",
    "submissions.to_csv('submission.csv', sep=',', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13c74a7391c7b6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
