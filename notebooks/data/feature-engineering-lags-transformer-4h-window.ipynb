{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b5b0c4",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30219bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T12:45:00.780002600Z",
     "start_time": "2023-09-29T12:44:58.091438100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc62c52",
   "metadata": {},
   "source": [
    "## Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a560c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T12:45:52.408420500Z",
     "start_time": "2023-09-29T12:45:00.786090800Z"
    }
   },
   "outputs": [],
   "source": [
    "IS_TRAINING = True\n",
    "if IS_TRAINING:\n",
    "    FILE = '../../data/processed/train_series_split_normalized.parquet'\n",
    "else:\n",
    "    FILE = '../../data/processed/validation_series_split_normalized.parquet'\n",
    "series = pd.read_parquet(FILE, columns=['num_series_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c9b53",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FREQ = 12 # 1 min\n",
    "SAMPLE_LEN = 120 # 2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAGS_FUTURE = [f\"t_lag_{i}\" for i in range(-1, -SAMPLE_LEN, -1)]\n",
    "LAGS_PAST = reversed([f\"t_lag_{i}\" for i in range(1, SAMPLE_LEN)])\n",
    "FEATURES = [*LAGS_PAST, 't_0', *LAGS_FUTURE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74cd20c7a91f81",
   "metadata": {},
   "source": [
    "## Neue Features erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25844b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"train/\" if IS_TRAINING else \"validation/\"\n",
    "file_path_prefix = \"../../data/processed/transformer-downsample/\" + folder\n",
    "\n",
    "def save_chunk(num_series_id, chunk):\n",
    "    series_length, series_columns = chunk[FEATURES].values.shape\n",
    "    X = torch.from_numpy(np.array(np.ravel(chunk[FEATURES].values).tolist())\n",
    "                           .reshape(series_length, series_columns, 2)).to(torch.float32)\n",
    "    torch.save(X, file_path_prefix + str(num_series_id) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02687bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    df['anglez'] = df['anglez'].rolling(SAMPLE_FREQ, center=True).agg('mean').bfill().ffill().values\n",
    "    df['enmo'] = df['enmo'].rolling(SAMPLE_FREQ, center=True).agg('mean').bfill().ffill().values\n",
    "    \n",
    "    return df.iloc[::SAMPLE_FREQ, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7819507cd29d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T12:45:52.429714800Z",
     "start_time": "2023-09-29T12:45:52.419364600Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_features_chunk(num_series_id):\n",
    "    df = pd.read_parquet(FILE, filters=[('num_series_id','=',num_series_id)])\n",
    "    df = downsample(df)\n",
    "    \n",
    "    df['t_0'] = df[['anglez', 'enmo']].values.tolist()\n",
    "\n",
    "    columns_past = []\n",
    "    for i in range(1, SAMPLE_LEN):\n",
    "        df[f'anglez_lag_{i}'] = df[\"anglez\"].shift(i).bfill()\n",
    "        df[f'enmo_lag_{i}'] = df[\"enmo\"].shift(i).bfill()\n",
    "        df[f't_lag_{i}'] = df[[f'anglez_lag_{i}', f'enmo_lag_{i}']].values.tolist()\n",
    "        columns_past.extend([f'anglez_lag_{i}', f'enmo_lag_{i}'])\n",
    "    df = df.drop(columns=columns_past)\n",
    "\n",
    "\n",
    "    columns_future = []\n",
    "    for i in range(-1, -1 * SAMPLE_LEN, -1):\n",
    "        df[f'anglez_lag_{i}'] = df[\"anglez\"].shift(i).ffill()\n",
    "        df[f'enmo_lag_{i}'] = df[\"enmo\"].shift(i).ffill()\n",
    "        df[f't_lag_{i}'] = df[[f'anglez_lag_{i}', f'enmo_lag_{i}']].values.tolist()\n",
    "        columns_future.extend([f'anglez_lag_{i}', f'enmo_lag_{i}'])\n",
    "    df = df.drop(columns=columns_future)\n",
    "\n",
    "    \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b52907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(series):\n",
    "    overview_data = []\n",
    "\n",
    "    for num_series_id in tqdm(series.num_series_id.unique()):\n",
    "        chunk = make_features_chunk(num_series_id)\n",
    "        save_chunk(num_series_id, chunk)\n",
    "        overview_data.append(\n",
    "            chunk[['num_series_id', 'step', 'awake', 'critical_event_point']].reset_index().rename(columns={'index':'series_index'}).copy()[['num_series_id', 'step', 'awake', 'critical_event_point', 'series_index']]\n",
    "        )\n",
    "    \n",
    "        del chunk\n",
    "        gc.collect()\n",
    "   \n",
    "    return pd.concat(overview_data).reset_index(drop=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d067155defaebc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-29T12:45:52.429714800Z"
    },
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "overview = make_features(series)\n",
    "print(f'Feature Engineering took {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5c218",
   "metadata": {},
   "source": [
    "## Overview speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d108c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-challenge",
   "language": "python",
   "name": "ai-challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
