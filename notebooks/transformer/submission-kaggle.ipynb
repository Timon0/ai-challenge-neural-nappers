{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from joblib import load\n",
    "import math\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Modeling\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "# Disable warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "LAGS_FUTURE = [f\"t_lag_{i}\" for i in range(-1, -25, -1)]\n",
    "LAGS_PAST = reversed([f\"t_lag_{i}\" for i in range(1, 25)])\n",
    "FEATURES = [*LAGS_PAST, 't_0', *LAGS_FUTURE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMS\n",
    "ANGLEZ_VARIANCE_SEQUENCE_LENGTH = 6 * 60 * 12 # 8h\n",
    "ANGLEZ_REPETITION_SEQUENCE_LENGTH = 4 * 60 * 12 # 4h\n",
    "\n",
    "CLEAN_BUFFER = 3 * 60 * 12 # 3h\n",
    "\n",
    "def mark_clean_anglez_too_low_variance(series):\n",
    "    last_step = series.iloc[-1]['step']       \n",
    "    \n",
    "    for current_start_step in range(0, len(series), ANGLEZ_VARIANCE_SEQUENCE_LENGTH):\n",
    "        current_end_step = current_start_step + ANGLEZ_VARIANCE_SEQUENCE_LENGTH\n",
    "\n",
    "        series_chunk = series[current_start_step:current_end_step]\n",
    "\n",
    "        series_chunk_anglez = series_chunk['anglez'].abs()\n",
    "        if not (series_chunk_anglez > 50).any():\n",
    "            clean_from = max(0, current_start_step - CLEAN_BUFFER)\n",
    "            clean_to = min(last_step, current_end_step + CLEAN_BUFFER)\n",
    "            \n",
    "            series.loc[clean_from:clean_to, 'clean'] = 1\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def mark_clean_repetition(series):\n",
    "    last_step = series.iloc[-1]['step']       \n",
    "\n",
    "    for current_start_step in range(0, len(series), ANGLEZ_REPETITION_SEQUENCE_LENGTH):\n",
    "        current_end_step = current_start_step + ANGLEZ_REPETITION_SEQUENCE_LENGTH\n",
    "\n",
    "        series_chunk = series[current_start_step:current_end_step].reset_index(drop=True)\n",
    "\n",
    "        for comparing_start_step in range(current_end_step, len(series), ANGLEZ_REPETITION_SEQUENCE_LENGTH):\n",
    "            comparing_end_step = comparing_start_step + ANGLEZ_REPETITION_SEQUENCE_LENGTH\n",
    "            comparing_series_chunk = series[comparing_start_step:comparing_end_step].reset_index(drop=True)\n",
    "\n",
    "            if series_chunk['anglez'].equals(comparing_series_chunk['anglez']):\n",
    "                clean_from = max(0, current_start_step - CLEAN_BUFFER)\n",
    "                clean_to = min(last_step, current_end_step + CLEAN_BUFFER)\n",
    "                series.loc[clean_from:clean_to, 'clean'] = 1\n",
    "                \n",
    "                clean_from = max(0, comparing_start_step - CLEAN_BUFFER)\n",
    "                clean_to = min(last_step, comparing_end_step + CLEAN_BUFFER)\n",
    "                series.loc[clean_from:clean_to, 'clean'] = 1\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def data_cleaning(series):\n",
    "    series['clean'] = 0\n",
    "\n",
    "    series = mark_clean_anglez_too_low_variance(series)\n",
    "    series = mark_clean_repetition(series)\n",
    "    \n",
    "    series = series[series.clean == 0]\n",
    "\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = load('/kaggle/input/transformer-checkpoint/scaler.pkl')\n",
    "scaler = load('../../data/processed/scaler.pkl')\n",
    "\n",
    "def data_normalization(series_to_normalize):\n",
    "    series_to_normalize[['enmo', 'anglez']] = scaler.transform(series_to_normalize[['enmo', 'anglez']])\n",
    "    return series_to_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_feature_engineering(series):\n",
    "\n",
    "    series['t_0'] = series[['anglez', 'enmo']].values.tolist()\n",
    "\n",
    "    for i in range(1, 25):\n",
    "        series[f'anglez_lag_{i}'] = series[\"anglez\"].shift(i).bfill()\n",
    "        series[f'enmo_lag_{i}'] = series[\"enmo\"].shift(i).bfill()\n",
    "        series[f't_lag_{i}'] = series[[f'anglez_lag_{i}', f'enmo_lag_{i}']].values.tolist()\n",
    "        series = series.drop(columns=[f'anglez_lag_{i}', f'enmo_lag_{i}'])\n",
    "\n",
    "    for i in range(-1, -25, -1):\n",
    "        series[f'anglez_lag_{i}'] = series[\"anglez\"].shift(i).ffill()\n",
    "        series[f'enmo_lag_{i}'] = series[\"enmo\"].shift(i).ffill()\n",
    "        series[f't_lag_{i}'] = series[[f'anglez_lag_{i}', f'enmo_lag_{i}']].values.tolist()\n",
    "        series = series.drop(columns=[f'anglez_lag_{i}', f'enmo_lag_{i}'])\n",
    "    \n",
    "    return series.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(series_id):\n",
    "    #series = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet', filters=[('series_id','=',series_id)])\n",
    "    series = pd.read_parquet('../../data/processed/validation_series_split.parquet', filters=[('series_id','=',series_id)])\n",
    "    series = data_cleaning(series)\n",
    "    series = data_normalization(series)\n",
    "    return data_feature_engineering(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, d_model, seq_len, n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(d_model * seq_len, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.seq(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features=2, encoder_layer_nhead=4, num_layers=2, dim_model=64, num_classes=2,\n",
    "                 sequence_length=49, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_type = 'Transformer'\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.encoder_layer_nhead = encoder_layer_nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_model = dim_model\n",
    "        self.num_classes = num_classes\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.embedding = nn.Linear(self.num_features, self.dim_model)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(self.dim_model, dropout, self.sequence_length)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.dim_model,\n",
    "                                                   nhead=self.encoder_layer_nhead,\n",
    "                                                   batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=self.num_layers)\n",
    "\n",
    "        self.classifier = ClassificationHead(seq_len=sequence_length, d_model=self.dim_model, n_classes=num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.embedding(src)\n",
    "        output = self.pos_encoder(output)\n",
    "        output = self.encoder(output)\n",
    "        return self.classifier(output)\n",
    "\n",
    "\n",
    "class LightningModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model=None, encoder_layer_nhead=4, num_layers=2, dim_model=64, learning_rate=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.sequence_length = 49\n",
    "        self.num_features = 2\n",
    "        self.num_classes = 2\n",
    "        self.encoder_layer_nhead = encoder_layer_nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_model = dim_model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        if model is None:\n",
    "            self.model = TransformerEncoderClassifier(self.num_features,\n",
    "                                                      self.encoder_layer_nhead,\n",
    "                                                      self.num_layers,\n",
    "                                                      self.dim_model,\n",
    "                                                      self.num_classes,\n",
    "                                                      self.sequence_length)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_length: int = 5000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          d_model:      dimension of embeddings\n",
    "          dropout:      randomly zeroes-out some of the input\n",
    "          max_length:   max sequence length\n",
    "        \"\"\"\n",
    "        # inherit from Module\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize dropout\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # create tensor of 0s\n",
    "        pe = torch.zeros(max_length, d_model)\n",
    "\n",
    "        # create position column\n",
    "        k = torch.arange(0, max_length).unsqueeze(1)\n",
    "\n",
    "        # calc divisor for positional encoding\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        # calc sine on even indices\n",
    "        pe[:, 0::2] = torch.sin(k * div_term)\n",
    "\n",
    "        # calc cosine on odd indices\n",
    "        pe[:, 1::2] = torch.cos(k * div_term)\n",
    "\n",
    "        # add dimension\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # buffers are saved in state_dict but not trained by the optimizer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x:        embeddings (batch_size, seq_length, d_model)\n",
    "\n",
    "        Returns:\n",
    "                    embeddings + positional encodings (batch_size, seq_length, d_model)\n",
    "        \"\"\"\n",
    "        # add positional encoding to the embeddings\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "\n",
    "        # perform dropout\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael Jakober\\anaconda3\\envs\\aich\\lib\\site-packages\\pytorch_lightning\\utilities\\migration\\utils.py:55: The loaded checkpoint was produced with Lightning v2.1.2, which is newer than your current Lightning version: v2.1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LightningModel(\n",
       "  (model): TransformerEncoderClassifier(\n",
       "    (embedding): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (pos_encoder): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): ClassificationHead(\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (seq): Sequential(\n",
       "        (0): Flatten(start_dim=1, end_dim=-1)\n",
       "        (1): Linear(in_features=3136, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (6): ReLU()\n",
       "        (7): Linear(in_features=128, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = LightningModel.load_from_checkpoint('/kaggle/input/transformer-checkpoint/transformer.ckpt')\n",
    "model = LightningModel.load_from_checkpoint('../../models/transformer/neural-nappers/613dj1tv/checkpoints/transformer.ckpt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_batch(batch):\n",
    "    X = batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(X.to(device))\n",
    "    label = torch.argmax(logits, dim=-1)\n",
    "    confidence = torch.softmax(logits, dim=-1)\n",
    "    confidence_0 = confidence[:, 0]\n",
    "    confidence_1 = confidence[:, 1]\n",
    "    return label, confidence_0, confidence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(series):\n",
    "    predictions = series[['series_id', 'step']]\n",
    "    \n",
    "    label_list = []\n",
    "    confidence_0_list = []\n",
    "    confidence_1_list = []\n",
    "    \n",
    "    series_length, series_columns = series[FEATURES].values.shape\n",
    "    start_time = time()\n",
    "    dataset = TensorDataset(torch.from_numpy(np.array(np.ravel(series[FEATURES].values).tolist())\n",
    "                                             .reshape(series_length, series_columns, 2)).to(torch.float32).to(device))\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=10000)\n",
    "    start_time = time()\n",
    "    for index, batch in enumerate(dataloader):\n",
    "        label, confidence_0, confidence_1 = prediction_batch(batch[0])\n",
    "        \n",
    "        label_list.append(label)\n",
    "        confidence_0_list.append(confidence_0)\n",
    "        confidence_1_list.append(confidence_1) \n",
    "\n",
    "    predictions['prediction_class'] = torch.cat(label_list).cpu().numpy()\n",
    "    predictions['prediction_confidence_0'] = torch.cat(confidence_0_list).cpu().numpy()\n",
    "    predictions['prediction_confidence_1'] = torch.cat(confidence_1_list).cpu().numpy()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_length = 12 * 60 # 60 Minutes\n",
    "\n",
    "def event_extraction(series):\n",
    "    events = []\n",
    "\n",
    "    series_id = series[\"series_id\"].values[0]\n",
    "               \n",
    "    series[\"confidence_awake\"] = series[\"prediction_confidence_1\"].rolling(smoothing_length, center=True).mean().bfill().ffill()\n",
    "    series[\"asleep\"] = series[\"prediction_confidence_0\"].rolling(smoothing_length, center=True).mean().bfill().ffill()\n",
    "\n",
    "    # Binarize the smoothing column\n",
    "    series[\"asleep\"] = series[\"asleep\"].round()\n",
    "\n",
    "    # Getting predicted onset and wakeup time steps\n",
    "    pred_onsets = series[series['asleep'].diff() > 0]['step'].tolist() # diff is > 0 if it changes from 0 (awake) to 1 (asleep)\n",
    "    pred_wakeups = series[series['asleep'].diff() < 0]['step'].tolist() # diff is < 0 if it changes from 1 (asleep) to 0 (awake)\n",
    "     \n",
    "    if len(pred_onsets) > 0 and len(pred_wakeups) > 0:\n",
    "\n",
    "        # Ensuring all predicted sleep periods begin and end\n",
    "        if min(pred_wakeups) < min(pred_onsets):\n",
    "            pred_wakeups = pred_wakeups[1:]\n",
    "\n",
    "        if max(pred_onsets) > max(pred_wakeups):\n",
    "            pred_onsets = pred_onsets[:-1]\n",
    "\n",
    "        # Keeping sleep periods longer than 30 minutes\n",
    "        sleep_periods = [(onset, wakeup) for onset, wakeup in zip(pred_onsets, pred_wakeups) if wakeup - onset >= 12 * 30]\n",
    "\n",
    "        for onset, wakeup in sleep_periods :\n",
    "            # Scoring using mean probability over period\n",
    "            score = 1 - series[(series['step'] >= onset) & (series['step'] < wakeup)]['confidence_awake'].mean()\n",
    "\n",
    "            # Adding sleep event to dataframe\n",
    "            onset_row = {'row_id': len(events), 'series_id': series_id, 'step': onset, 'event': 'onset', 'score': score}                \n",
    "            events.append(onset_row)\n",
    "\n",
    "            wakeup_row = {'row_id': len(events), 'series_id': series_id, 'step': wakeup, 'event': 'wakeup', 'score': score}\n",
    "            events.append(wakeup_row)\n",
    "\n",
    "    return pd.DataFrame(events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet', columns=['series_id'])\n",
    "df_test = pd.read_parquet('../../data/processed/validation_series_split.parquet', columns=['series_id'])\n",
    "series_ids = df_test.series_id.unique()[1:2]\n",
    "del df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 of 1\n",
      "tensor([0.9998, 0.9999, 0.9999,  ..., 0.9997, 0.9996, 0.9994])\n",
      "tensor([0.9992, 0.9990, 0.9989,  ..., 0.9855, 0.9670, 0.9534])\n",
      "tensor([0.9494, 0.9522, 0.9238,  ..., 0.9984, 0.9960, 0.9892])\n",
      "tensor([0.9824, 0.9691, 0.9516,  ..., 0.0374, 0.0374, 0.0374])\n",
      "tensor([0.0374, 0.0374, 0.0374,  ..., 0.9981, 0.9987, 0.9985])\n",
      "tensor([0.9981, 0.9979, 0.9977,  ..., 0.0366, 0.0366, 0.0366])\n",
      "tensor([0.0366, 0.0366, 0.0366,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([1.0000, 1.0000, 0.9999,  ..., 0.2639, 0.2871, 0.3357])\n",
      "tensor([0.4140, 0.5051, 0.5546,  ..., 0.9553, 0.9782, 0.9723])\n",
      "tensor([0.9762, 0.9942, 0.9918,  ..., 0.9707, 0.9788, 0.9856])\n",
      "tensor([0.9879, 0.9796, 0.9800,  ..., 0.5764, 0.5415, 0.4067])\n",
      "tensor([0.4258, 0.4894, 0.5042,  ..., 0.9969, 0.9968, 0.9977])\n",
      "tensor([0.9978, 0.9980, 0.9986,  ..., 0.5884, 0.6025, 0.5802])\n",
      "tensor([0.5192, 0.5412, 0.5841,  ..., 0.9999, 0.9999, 0.9999])\n",
      "tensor([0.9999, 0.9999, 0.9999,  ..., 0.9994, 0.9993, 0.9982])\n",
      "tensor([0.9982, 0.9981, 0.9988,  ..., 0.9994, 0.9995, 0.9995])\n",
      "tensor([0.9995, 0.9995, 0.9993,  ..., 0.9914, 0.9900, 0.9890])\n",
      "tensor([0.9914, 0.9895, 0.9924,  ..., 0.0493, 0.0493, 0.0493])\n",
      "tensor([0.0493, 0.0493, 0.0493,  ..., 0.9958, 0.9969, 0.9978])\n",
      "tensor([0.9975, 0.9972, 0.9977,  ..., 0.0364, 0.0365, 0.0365])\n",
      "tensor([0.0365, 0.0365, 0.0365,  ..., 0.9963, 0.9956, 0.9960])\n",
      "tensor([0.9992, 0.9996, 0.9997,  ..., 0.9453, 0.8935, 0.7004])\n",
      "tensor([0.7485, 0.7849, 0.7939,  ..., 0.6045, 0.7195, 0.6779])\n",
      "tensor([0.6469, 0.6785, 0.7597,  ..., 0.0313, 0.0313, 0.0314])\n",
      "tensor([0.0314, 0.0314, 0.0314,  ..., 0.4200, 0.4618, 0.4683])\n",
      "tensor([0.4781, 0.4598, 0.4505,  ..., 0.9999, 0.9999, 0.9999])\n",
      "tensor([0.9999, 0.9999, 0.9999,  ..., 0.2312, 0.3096, 0.3141])\n",
      "tensor([0.3693, 0.4111, 0.4284,  ..., 0.9509, 0.9488, 0.9491])\n"
     ]
    }
   ],
   "source": [
    "events_list = []\n",
    "\n",
    "for i, series_id in enumerate(series_ids):\n",
    "    print(f'Step {i+1} of {len(series_ids)}')\n",
    "    series_prepared = data_pipeline(series_id)\n",
    "    predictions = prediction(series_prepared)\n",
    "    events = event_extraction(predictions)\n",
    "\n",
    "    events_list.append(events)\n",
    "\n",
    "    del series_prepared\n",
    "    del predictions\n",
    "    gc.collect()\n",
    "\n",
    "events = pd.concat(events_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = events\n",
    "submissions.reset_index(inplace=True)\n",
    "submissions.rename(columns={\"index\": \"row_id\"}, inplace=True)\n",
    "submissions.to_csv('submission.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>5497</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.871390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>9387</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.871390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>10341</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.719725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>11202</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.719725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>12233</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.778423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>13487</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.778423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>23465</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.858795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>29529</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.858795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>37880</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.876353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>45348</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.876353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>56720</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.887847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>62965</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.887847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>73608</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.862441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>80441</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.862441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>90666</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.730254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>98008</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.730254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>108352</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.724111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>114612</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.724111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>122965</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.893456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>134812</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.893456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>143509</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>149172</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>178069</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.680701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>184254</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.680701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>194661</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.872931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>201222</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.872931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>212151</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.881274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>218714</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.881274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>228661</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.742229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>229695</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.742229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>229909</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>235572</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>247189</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>252852</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>257012</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.863505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>260615</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.863505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>264469</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>270132</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>281749</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0cd1e3d0ed95</td>\n",
       "      <td>287412</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.688082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  row_id     series_id    step   event     score\n",
       "0        0       0  0cd1e3d0ed95    5497   onset  0.871390\n",
       "1        1       1  0cd1e3d0ed95    9387  wakeup  0.871390\n",
       "2        2       2  0cd1e3d0ed95   10341   onset  0.719725\n",
       "3        3       3  0cd1e3d0ed95   11202  wakeup  0.719725\n",
       "4        4       4  0cd1e3d0ed95   12233   onset  0.778423\n",
       "5        5       5  0cd1e3d0ed95   13487  wakeup  0.778423\n",
       "6        6       6  0cd1e3d0ed95   23465   onset  0.858795\n",
       "7        7       7  0cd1e3d0ed95   29529  wakeup  0.858795\n",
       "8        8       8  0cd1e3d0ed95   37880   onset  0.876353\n",
       "9        9       9  0cd1e3d0ed95   45348  wakeup  0.876353\n",
       "10      10      10  0cd1e3d0ed95   56720   onset  0.887847\n",
       "11      11      11  0cd1e3d0ed95   62965  wakeup  0.887847\n",
       "12      12      12  0cd1e3d0ed95   73608   onset  0.862441\n",
       "13      13      13  0cd1e3d0ed95   80441  wakeup  0.862441\n",
       "14      14      14  0cd1e3d0ed95   90666   onset  0.730254\n",
       "15      15      15  0cd1e3d0ed95   98008  wakeup  0.730254\n",
       "16      16      16  0cd1e3d0ed95  108352   onset  0.724111\n",
       "17      17      17  0cd1e3d0ed95  114612  wakeup  0.724111\n",
       "18      18      18  0cd1e3d0ed95  122965   onset  0.893456\n",
       "19      19      19  0cd1e3d0ed95  134812  wakeup  0.893456\n",
       "20      20      20  0cd1e3d0ed95  143509   onset  0.688082\n",
       "21      21      21  0cd1e3d0ed95  149172  wakeup  0.688082\n",
       "22      22      22  0cd1e3d0ed95  178069   onset  0.680701\n",
       "23      23      23  0cd1e3d0ed95  184254  wakeup  0.680701\n",
       "24      24      24  0cd1e3d0ed95  194661   onset  0.872931\n",
       "25      25      25  0cd1e3d0ed95  201222  wakeup  0.872931\n",
       "26      26      26  0cd1e3d0ed95  212151   onset  0.881274\n",
       "27      27      27  0cd1e3d0ed95  218714  wakeup  0.881274\n",
       "28      28      28  0cd1e3d0ed95  228661   onset  0.742229\n",
       "29      29      29  0cd1e3d0ed95  229695  wakeup  0.742229\n",
       "30      30      30  0cd1e3d0ed95  229909   onset  0.688082\n",
       "31      31      31  0cd1e3d0ed95  235572  wakeup  0.688082\n",
       "32      32      32  0cd1e3d0ed95  247189   onset  0.688082\n",
       "33      33      33  0cd1e3d0ed95  252852  wakeup  0.688082\n",
       "34      34      34  0cd1e3d0ed95  257012   onset  0.863505\n",
       "35      35      35  0cd1e3d0ed95  260615  wakeup  0.863505\n",
       "36      36      36  0cd1e3d0ed95  264469   onset  0.688082\n",
       "37      37      37  0cd1e3d0ed95  270132  wakeup  0.688082\n",
       "38      38      38  0cd1e3d0ed95  281749   onset  0.688082\n",
       "39      39      39  0cd1e3d0ed95  287412  wakeup  0.688082"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6589269,
     "sourceId": 53666,
     "sourceType": "competition"
    },
    {
     "datasetId": 4011077,
     "sourceId": 6980087,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "aich",
   "language": "python",
   "name": "aich"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
