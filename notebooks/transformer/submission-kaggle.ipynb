{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from joblib import load\n",
    "import math\n",
    "\n",
    "# Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Modeling\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "import lightning as L\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scoring.event_detection_matrix import competition_score\n",
    "\n",
    "# Disable warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb338a493fa4a3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "LAGS_FUTURE = [f\"t_lag_{i}\" for i in range(-1, -25, -1)]\n",
    "LAGS_PAST = reversed([f\"t_lag_{i}\" for i in range(1, 25)])\n",
    "FEATURES = [*LAGS_PAST, 't_0', *LAGS_FUTURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ad6fc04977a39",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b706519df19843",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ec9ec9a26b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 24 * 60 * 12 # 17280 Steps = 1 Day\n",
    "\n",
    "def data_cleaning(series_to_clean):\n",
    "    multiplicator = 0\n",
    "\n",
    "    indices_to_remove = []\n",
    "\n",
    "    while True:\n",
    "        # Get 24 Hours (s1) and the next 24 Hours (s2)\n",
    "        s1 = series_to_clean[multiplicator*sequence_length:(multiplicator+1)*sequence_length]['anglez'].reset_index(drop=True)\n",
    "        s2 = series_to_clean[(multiplicator+1)*sequence_length:(multiplicator+2)*sequence_length]['anglez'].reset_index(drop=True)\n",
    "\n",
    "        # If the length is not the same, its the last part of the series\n",
    "        if len(s1) != len(s2):\n",
    "            # If the last part of the series is the same as the part 24 hours before, remove that as well\n",
    "            if s1[:len(s2)].equals(s2):\n",
    "                indices_to_remove.append((len(series_to_clean)-len(s2), len(series_to_clean)))\n",
    "            break\n",
    "\n",
    "        # If the 24 hours match, remove those indices\n",
    "        if s1.equals(s2):\n",
    "            indices_to_remove.append(((multiplicator+1)*sequence_length, (multiplicator+2)*sequence_length))\n",
    "\n",
    "        multiplicator += 1\n",
    "\n",
    "\n",
    "    cleaned_df = series_to_clean\n",
    "\n",
    "    # Remove the indices reversed, otherwise the indices of the remaining rows change\n",
    "    for start_idx, end_idx in reversed(indices_to_remove):\n",
    "        cleaned_df = cleaned_df.drop(index=cleaned_df.iloc[start_idx:end_idx].index)\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec5be12ccae8b2",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3853038e7bafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = load('/kaggle/input/sleep-detection-mlp-v1/scaler.pkl')\n",
    "scaler = load('../../data/processed/scaler.pkl')\n",
    "\n",
    "def data_normalization(series_to_normalize):\n",
    "    series_to_normalize[['enmo', 'anglez']] = scaler.transform(series_to_normalize[['enmo', 'anglez']])\n",
    "    return series_to_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a9d4db0f39b79",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752456becb66dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_feature_engineering(series):\n",
    "\n",
    "    series['t_0'] = series[['anglez', 'enmo']].values.tolist()\n",
    "\n",
    "    for i in range(1, 25):\n",
    "        series[f'anglez_lag_{i}'] = series[\"anglez\"].shift(i).bfill()\n",
    "        series[f'enmo_lag_{i}'] = series[\"enmo\"].shift(i).bfill()\n",
    "        series[f't_lag_{i}'] = series[[f'anglez_lag_{i}', f'enmo_lag_{i}']].values.tolist()\n",
    "        series = series.drop(columns=[f'anglez_lag_{i}', f'enmo_lag_{i}'])\n",
    "\n",
    "    for i in range(-1, -25, -1):\n",
    "        series[f'anglez_lag_{i}'] = series[\"anglez\"].shift(i).ffill()\n",
    "        series[f'enmo_lag_{i}'] = series[\"enmo\"].shift(i).ffill()\n",
    "        series[f't_lag_{i}'] = series[[f'anglez_lag_{i}', f'enmo_lag_{i}']].values.tolist()\n",
    "        series = series.drop(columns=[f'anglez_lag_{i}', f'enmo_lag_{i}'])\n",
    "    \n",
    "    return series.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e913b8623306e",
   "metadata": {},
   "source": [
    "### Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8cfff6ec831169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(series_id):\n",
    "    #series = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet', filters=[('series_id','=',series_id)])\n",
    "    series = pd.read_parquet('../../data/processed/validation_series_split.parquet', filters=[('series_id','=',series_id)])\n",
    "    series = data_cleaning(series)\n",
    "    series = data_normalization(series)\n",
    "    return data_feature_engineering(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219c23663a93566",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcca139020e490",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eddccc5d709cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, d_model, seq_len, n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(d_model * seq_len, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.seq(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features=2, encoder_layer_nhead=4, num_layers=2, dim_model=64, num_classes=2,\n",
    "                 sequence_length=49, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_type = 'Transformer'\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.encoder_layer_nhead = encoder_layer_nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_model = dim_model\n",
    "        self.num_classes = num_classes\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.embedding = nn.Linear(self.num_features, self.dim_model)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(self.dim_model, dropout, self.sequence_length)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.dim_model,\n",
    "                                                   nhead=self.encoder_layer_nhead,\n",
    "                                                   batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=self.num_layers)\n",
    "\n",
    "        self.classifier = ClassificationHead(seq_len=sequence_length, d_model=self.dim_model, n_classes=num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.embedding(src)\n",
    "        output = self.pos_encoder(output)\n",
    "        output = self.encoder(output)\n",
    "        return self.classifier(output)\n",
    "\n",
    "\n",
    "class LightningModel(L.LightningModule):\n",
    "\n",
    "    def __init__(self, model=None, encoder_layer_nhead=4, num_layers=2, dim_model=64, learning_rate=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.sequence_length = 49\n",
    "        self.num_features = 2\n",
    "        self.num_classes = 2\n",
    "        self.encoder_layer_nhead = encoder_layer_nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_model = dim_model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        if model is None:\n",
    "            self.model = TransformerEncoderClassifier(self.num_features,\n",
    "                                                      self.encoder_layer_nhead,\n",
    "                                                      self.num_layers,\n",
    "                                                      self.dim_model,\n",
    "                                                      self.num_classes,\n",
    "                                                      self.sequence_length)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "        # metrics\n",
    "        metrics = MetricCollection([\n",
    "            MulticlassAccuracy(num_classes=self.num_classes),\n",
    "            MulticlassPrecision(num_classes=self.num_classes),\n",
    "            MulticlassRecall(num_classes=self.num_classes),\n",
    "            MulticlassF1Score(num_classes=self.num_classes)\n",
    "        ])\n",
    "        self.train_metrics = metrics.clone(prefix='train_')\n",
    "        self.val_metrics = metrics.clone(prefix='val_')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, true_labels, logits = self._shared_step(batch)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        self.train_metrics(logits, true_labels)\n",
    "        self.log_dict(self.train_metrics, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        loss, true_labels, logits = self._shared_step(batch)\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "        self.val_metrics(logits, true_labels)\n",
    "        self.log_dict(self.val_metrics)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "        scheduler = LinearLR(optimizer, start_factor=1.0, end_factor=0.001, total_iters=self._num_steps())\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def _shared_step(self, batch):\n",
    "        features, true_labels = batch\n",
    "        logits = self(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, true_labels)\n",
    "        return loss, true_labels, logits\n",
    "\n",
    "    def _num_steps(self):\n",
    "        train_dataloader = self.trainer.datamodule.train_dataloader()\n",
    "        dataset_size = len(train_dataloader.dataset)\n",
    "        num_steps = dataset_size * self.trainer.max_epochs // self.trainer.datamodule.batch_size\n",
    "        return num_steps\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_length: int = 5000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          d_model:      dimension of embeddings\n",
    "          dropout:      randomly zeroes-out some of the input\n",
    "          max_length:   max sequence length\n",
    "        \"\"\"\n",
    "        # inherit from Module\n",
    "        super().__init__()\n",
    "\n",
    "        # initialize dropout\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # create tensor of 0s\n",
    "        pe = torch.zeros(max_length, d_model)\n",
    "\n",
    "        # create position column\n",
    "        k = torch.arange(0, max_length).unsqueeze(1)\n",
    "\n",
    "        # calc divisor for positional encoding\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        # calc sine on even indices\n",
    "        pe[:, 0::2] = torch.sin(k * div_term)\n",
    "\n",
    "        # calc cosine on odd indices\n",
    "        pe[:, 1::2] = torch.cos(k * div_term)\n",
    "\n",
    "        # add dimension\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # buffers are saved in state_dict but not trained by the optimizer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x:        embeddings (batch_size, seq_length, d_model)\n",
    "\n",
    "        Returns:\n",
    "                    embeddings + positional encodings (batch_size, seq_length, d_model)\n",
    "        \"\"\"\n",
    "        # add positional encoding to the embeddings\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "\n",
    "        # perform dropout\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13383d4f4a8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LightningModel.load_from_checkpoint('/kaggle/input/sleep-detection-mlp-v1/mlp-2zhn0l6i.ckpt')\n",
    "model = LightningModel.load_from_checkpoint('../../models/transformer/neural-nappers/pei7u45k/checkpoints/transformer.ckpt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6a4fd31fccd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_batch(batch):\n",
    "    X = batch\n",
    "    with torch.no_grad():\n",
    "        logits = model(X.to('cuda'))\n",
    "    label = torch.argmax(logits, dim=-1)\n",
    "    confidence = torch.softmax(logits, dim=-1)\n",
    "    confidence_0 = confidence[:, 0]\n",
    "    confidence_1 = confidence[:, 1]\n",
    "    return label, confidence_0, confidence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d181bf40b9aa1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(series):\n",
    "    predictions = series[['series_id', 'step']]\n",
    "    \n",
    "    label_list = []\n",
    "    confidence_0_list = []\n",
    "    confidence_1_list = []\n",
    "    \n",
    "    dataset = TensorDataset(torch.from_numpy(series[FEATURES].values))\n",
    "    dataloader = DataLoader(dataset, batch_size=10000)\n",
    "    for index, batch in enumerate(dataloader): \n",
    "        label, confidence_0, confidence_1 = prediction_batch(batch[0])\n",
    "        \n",
    "        label_list.append(label)\n",
    "        confidence_0_list.append(confidence_0)\n",
    "        confidence_1_list.append(confidence_1) \n",
    "        \n",
    "    predictions['prediction_class'] = torch.cat(label_list).cpu().numpy()\n",
    "    predictions['prediction_confidence_0'] = torch.cat(confidence_0_list).cpu().numpy()\n",
    "    predictions['prediction_confidence_1'] = torch.cat(confidence_1_list).cpu().numpy()\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2957e3b1ef313",
   "metadata": {},
   "source": [
    "## Event Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b3c24c962fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_length = 12 * 30 # 30 Minutes\n",
    "\n",
    "def event_extraction(series):\n",
    "    events = []\n",
    "\n",
    "    series_id = series[\"series_id\"].values[0]\n",
    "               \n",
    "    series[\"score\"] = series[\"prediction_confidence_1\"].rolling(smoothing_length, center=True).mean().bfill().ffill()\n",
    "    series[\"smooth\"] = series[\"prediction_confidence_0\"].rolling(smoothing_length, center=True).mean().bfill().ffill()\n",
    "\n",
    "    # Binarize the smoothing column\n",
    "    series[\"smooth\"] = series[\"smooth\"].round()\n",
    "\n",
    "    # Getting predicted onset and wakeup time steps\n",
    "    pred_onsets = series[series['smooth'].diff() > 0]['step'].tolist()\n",
    "    pred_wakeups = series[series['smooth'].diff() < 0]['step'].tolist()\n",
    "     \n",
    "    if len(pred_onsets) > 0 : \n",
    "\n",
    "    # Ensuring all predicted sleep periods begin and end\n",
    "        if min(pred_wakeups) < min(pred_onsets) : \n",
    "            pred_wakeups = pred_wakeups[1:]\n",
    "\n",
    "        if max(pred_onsets) > max(pred_wakeups) :\n",
    "            pred_onsets = pred_onsets[:-1]\n",
    "\n",
    "        # Keeping sleep periods longer than 30 minutes\n",
    "        sleep_periods = [(onset, wakeup) for onset, wakeup in zip(pred_onsets, pred_wakeups) if wakeup - onset >= 12 * 30]\n",
    "\n",
    "        for onset, wakeup in sleep_periods :\n",
    "            # Scoring using mean probability over period\n",
    "            score = series[(series['step'] >= onset) & (series['step'] <= wakeup)]['score'].mean()\n",
    "\n",
    "            # Adding sleep event to dataframe\n",
    "            onset_row = {'row_id': len(events), 'series_id': series_id, 'step': onset, 'event': 'onset', 'score': score}                \n",
    "            events.append(onset_row)\n",
    "\n",
    "            wakeup_row = {'row_id': len(events), 'series_id': series_id, 'step': wakeup, 'event': 'wakeup', 'score': score}\n",
    "            events.append(wakeup_row)\n",
    "\n",
    "    return pd.DataFrame(events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ab206e954d07d",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d9dda1c16b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet', columns=['series_id'])\n",
    "df_test = pd.read_parquet('../../data/processed/validation_series_split.parquet', columns=['series_id'])\n",
    "series_ids = df_test.series_id.unique()\n",
    "del df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984b6235963e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list = []\n",
    "\n",
    "for i, series_id in enumerate(series_ids):\n",
    "    print(f'Step {i+1} of {len(series_ids)}')\n",
    "    series_prepared = data_pipeline(series_id)\n",
    "    predictions = prediction(series_prepared)\n",
    "    events = event_extraction(predictions)\n",
    "    \n",
    "    events_list.append(events)\n",
    "        \n",
    "    del series_prepared\n",
    "    del predictions\n",
    "    gc.collect()\n",
    "\n",
    "events = pd.concat(events_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955f5e4a50402d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = events\n",
    "submissions.reset_index(inplace=True)\n",
    "submissions.rename(columns={\"index\": \"row_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a92295e12cb49",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259b5a50ec374c1",
   "metadata": {},
   "source": [
    "### Competition Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100384625d15025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_events = pd.read_csv('../../data/processed/validation_events_split.csv')\n",
    "df_validation_events = df_validation_events[df_validation_events.step.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56b99c9b04e7dbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14722090931389065"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_score(df_validation_events, submissions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
